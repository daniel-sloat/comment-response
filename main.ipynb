{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes input from xlsx spredsheet that has comments listed per row with grouping categories specified into two or three headings, and outputs a docx document that is grouped by those headings, with comments listed under the lowest-tier heading and response following. The response must be on the first row of a grouping, with other response rows under the same grouping being blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //TODO Create toml configuration file\n",
    "# //TODO Make sure that the first nonempty response is taken for each comment grouping\n",
    "# //TODO Finalize and create another requirements.txt with only needed requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import docx_tools\n",
    "import win32_tools\n",
    "import ooxml\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment_index_tags(\n",
    "    df_worksheet: pd.DataFrame, \n",
    "    comment_tag_column: str\n",
    ") -> pd.Series:\n",
    "    \"\"\"Create comment index tags to be appended to the end of comments for identification.\n",
    "    Once comment index tags are created and appended, can be used with AutoMark to create index.\n",
    "\n",
    "    Args:\n",
    "        df_worksheet (pd.DataFrame): Dataframe representation of worksheet.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Comment index tags.\n",
    "    \"\"\"\n",
    "    # Regex captures two groups: (1) filename without extension, and (2) the file extension.\n",
    "    # Also covers files starting with \".\", common on Unix.\n",
    "    regex = r\"(?P<filename>.+?)(?P<ext>\\.[^.]*$|$)\"\n",
    "    # Prefix and suffix added in attempt to make sure only unique identifiers are marked.\n",
    "    replacement = f\"zyx\\\\1xyz\"\n",
    "    comment_tags = df_worksheet[comment_tag_column].str.replace(regex,replacement,regex=True)\n",
    "    comment_tags.name = \"CommentTags\"\n",
    "    return comment_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_comment_tags(\n",
    "    comment_column_list: list,\n",
    "    comment_tags: pd.Series\n",
    ") -> list:\n",
    "    \"\"\"Appends tags to the end of each comment.\n",
    "\n",
    "    Args:\n",
    "        comment_column_list (list): Untagged comment list.\n",
    "        comment_tags (pd.Series): Tags to append.\n",
    "\n",
    "    Returns:\n",
    "        list: Tagged comment list.\n",
    "    \"\"\"\n",
    "    for cmt, tag in zip(comment_column_list,comment_tags):\n",
    "        for para in cmt:\n",
    "            if para == cmt[-1]:\n",
    "                tag_run = (\"\",\" (\" + tag + \")\")\n",
    "                para.append(tag_run)\n",
    "    return comment_column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def working_df(\n",
    "    df_worksheet: pd.DataFrame,\n",
    "    comment_col: list,\n",
    "    response_col: list,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"A \"working\" dataframe that includes relevant columns\n",
    "    for subsequent steps of combining and grouping to get\n",
    "    into format suitable for writing docx file.\n",
    "\n",
    "    Args:\n",
    "        df_worksheet (pd.DataFrame): \n",
    "            DataFrame of plain sharedStrings.\n",
    "        comment_col (list): For rich text:\n",
    "            [Comment[Paragraph[Run[Format,RunText]]]]\n",
    "        response_col (list): For rich text:\n",
    "            [Response[Paragraph[Run[Format,RunText]]]]\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Focused dataframe used for grouping.\n",
    "    \"\"\"\n",
    "    df_sheet = df_worksheet[[LEVEL_1,LEVEL_2,LEVEL_3]].copy()\n",
    "    df_sheet[COMMENTS_COLUMN] = comment_col\n",
    "    df_sheet[RESPONSE_COLUMN] = response_col\n",
    "    return df_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_comments_and_responses(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Group comments at lowest-level of hierarchy. Counts\n",
    "    the number of comments in the group.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Relevant dataframe (grouping columns, \n",
    "        comment column)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Grouped at lowest-level hierarchy with \n",
    "        comment count.\n",
    "    \"\"\"\n",
    "    df_group = df.groupby([LEVEL_1,LEVEL_2,LEVEL_3],dropna=False)\n",
    "    comments_grouped = df_group[COMMENTS_COLUMN].apply(tuple)\n",
    "    comment_count = df_group[COMMENTS_COLUMN].count().rename(\"CommentCount\")\n",
    "    responses = df_group[RESPONSE_COLUMN].first()\n",
    "    # Comment groups with no response will not be iterable (NoneType). \n",
    "    # Replace with empty run: (Response[Para(Run)])\n",
    "    empty_response = ([(\"\",\"\")],)\n",
    "    responses = responses.apply(\n",
    "        lambda x: x if isinstance(x, tuple | list) else empty_response\n",
    "        )\n",
    "    response_count = df_group[RESPONSE_COLUMN].count().rename(\"ResponseCount\")\n",
    "    concat = pd.concat(\n",
    "        [comments_grouped, comment_count, responses, response_count],\n",
    "        axis=1\n",
    "        ).reset_index()\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_response_count(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Raises message regarding number of responses. If number\n",
    "    of responses != 1, show error message.\n",
    "\n",
    "    Args:\n",
    "        responses_with_count (pd.DataFrame): Grouped with \n",
    "        response count.\n",
    "    \"\"\"\n",
    "    count = df[\"ResponseCount\"]\n",
    "    if count.max() > 1:\n",
    "        print(\"ERROR: More than one response for at least one comment group detected. \"\n",
    "              + \"Keeping only the first response (which may not be desired).\")\n",
    "    if count.min() < 1:\n",
    "        print(\"WARNING: No response for at least one comment group detected. \"\n",
    "              + \"Empty response inserted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting(sort: int=0) -> tuple:\n",
    "    match sort:\n",
    "        case 'alpha':\n",
    "            print(\"Sorting alphabetically (ascending).\")\n",
    "            level3_columns = [LEVEL_1,LEVEL_2,LEVEL_3]\n",
    "            level3_ascending = [True,True,True]\n",
    "            level2_columns = [LEVEL_1,LEVEL_2]\n",
    "            level2_ascending = [True,True]\n",
    "        case 'count':\n",
    "            print(\"Sorting by comment count (descending).\")\n",
    "            level3_columns = [LEVEL_1,LEVEL_2,\"CommentCount\",LEVEL_3]\n",
    "            level3_ascending = [True,True,False,True]\n",
    "            level2_columns = [LEVEL_1,\"CommentCount\",LEVEL_2]\n",
    "            level2_ascending = [True,False,True]\n",
    "        case _:\n",
    "            print(\"No sorting.\")\n",
    "            return None\n",
    "    return level3_columns, level3_ascending, level2_columns, level2_ascending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_level(df: pd.DataFrame) -> tuple:\n",
    "    LEVEL_3_DATA = \"Level3Data\"\n",
    "    LEVEL_2_DATA = \"Level2Data\"\n",
    "    LEVEL_1_DATA = \"Level1Data\"\n",
    "    sort = sorting(SORT)\n",
    "    \n",
    "    def level3(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        if sort:\n",
    "            df = df.sort_values(\n",
    "                by=sort[0], \n",
    "                ascending=sort[1],\n",
    "                ).reset_index(drop=True)\n",
    "        df[LEVEL_3] = df[LEVEL_3].fillna(\"Blank\")\n",
    "        df[LEVEL_3_DATA] = tuple(zip(\n",
    "            df[COMMENTS_COLUMN],df[LEVEL_3],df[RESPONSE_COLUMN]\n",
    "            ))\n",
    "        return df\n",
    "    \n",
    "    def level2(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_group = df.groupby([LEVEL_1,LEVEL_2])\n",
    "        comments_level_2 = df_group[LEVEL_3_DATA].apply(tuple)\n",
    "        df = pd.DataFrame(comments_level_2).reset_index()\n",
    "        if sort:\n",
    "            comment_count = df_group[\"CommentCount\"].first()\n",
    "            df = pd.merge(\n",
    "                comments_level_2,comment_count,\n",
    "                left_index=True,right_index=True\n",
    "                ).reset_index()\n",
    "            df = df.sort_values(\n",
    "                by=sort[2], \n",
    "                ascending=sort[3],\n",
    "                ).reset_index(drop=True)\n",
    "        df[LEVEL_2_DATA] = tuple(zip(\n",
    "            df[LEVEL_3_DATA], df[LEVEL_2]\n",
    "            ))\n",
    "        return df\n",
    "    \n",
    "    def level1(df: pd.DataFrame) -> tuple:\n",
    "        df_group = df.groupby([LEVEL_1])\n",
    "        comments_level_1 = df_group[LEVEL_2_DATA].apply(tuple)\n",
    "        df = pd.DataFrame(comments_level_1).reset_index()\n",
    "        if LEVEL_1_SORT:\n",
    "            df_mapping = pd.DataFrame({\"sort\": LEVEL_1_SORT})\n",
    "            sort_mapping = df_mapping.reset_index().set_index(\"sort\")\n",
    "            df[\"sort\"] = df[LEVEL_1].map(sort_mapping[\"index\"])\n",
    "            df = df.sort_values(\"sort\").reset_index()\n",
    "        df[LEVEL_1_DATA] = tuple(zip(\n",
    "            df[LEVEL_2_DATA], df[LEVEL_1]\n",
    "            ))\n",
    "        return tuple(df[LEVEL_1_DATA])\n",
    "\n",
    "    return level1(level2(level3(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_index_entries(comment_tags: list) -> None:\n",
    "    \"\"\"Mark index entries by creating AutoMark document\n",
    "    and opening Word and marking entries, and adding\n",
    "    index.\n",
    "\n",
    "    Args:\n",
    "        comment_tags (list): Comment tags to index.\n",
    "    \"\"\"\n",
    "    regex = f\"^zyx((\\d+?)-(.+?))xyz$\"\n",
    "    index_entry = comment_tags.replace(regex,r\"\\1\",regex=True)\n",
    "    automark_list = list(zip(comment_tags,index_entry))\n",
    "    docx_tools.automarkdoc(automark_list)\n",
    "    # win32_tools requires Office to be installed.\n",
    "    win32_tools.mark_index_entries(add_index=True)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Read ooxml file and retrieve relevant data\n",
    "    ooxml_file = ooxml.SpreadSheetML(FILENAME)\n",
    "    sheet = ooxml_file.sheet(SHEETNAME)\n",
    "    coded_sheet = sheet.to_dataframe_codes()\n",
    "    # Remove empty comment rows. All rows should have a comment associated with it.\n",
    "    remove_empty_comment_rows = coded_sheet[COMMENTS_COLUMN].notna()\n",
    "    coded_sheet = coded_sheet[remove_empty_comment_rows]\n",
    "    sharedstrings_rich = sheet.get_rich_strings()\n",
    "    df_worksheet = sheet.to_dataframe()\n",
    "    df_worksheet = df_worksheet[remove_empty_comment_rows]\n",
    "    comment_codes = coded_sheet[COMMENTS_COLUMN]\n",
    "    response_codes = coded_sheet[RESPONSE_COLUMN]\n",
    "    comment_tags = get_comment_index_tags(df_worksheet,COMMENT_TAGS_COLUMN)\n",
    "    # Decode comment and response columns\n",
    "    comment_code_data = ooxml.RichText(sharedstrings_rich,comment_codes)\n",
    "    response_code_data = ooxml.RichText(sharedstrings_rich,response_codes)\n",
    "    formats = list(set(comment_code_data.formats_used()\n",
    "                       + response_code_data.formats_used()))\n",
    "    comment_column_list = comment_code_data.decode()\n",
    "    response_column_list = response_code_data.decode()\n",
    "    comment_column_list = append_comment_tags(comment_column_list,comment_tags)\n",
    "    df_working = working_df(df_worksheet,comment_column_list,response_column_list)\n",
    "    comments_and_response = group_comments_and_responses(df_working)\n",
    "    check_response_count(comments_and_response)\n",
    "    # Group headings, comments, and responses into multi-level list\n",
    "    grouped = group_by_level(comments_and_response)\n",
    "    docx_tools.commentsectiondoc(grouped,formats,levels=3)\n",
    "    mark_index_entries(comment_tags)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd3fbca0973d0de72f98febb6a4138317bec6e91b52e16123d6d8b228c92bab3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
